<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="public/css/style.css">
    <link href='https://fonts.googleapis.com/css?family=Quicksand' rel='stylesheet'>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/assets/owl.carousel.css">
    <title>İTÜ Simit Lab</title>
    <meta name="description" content="Smart Interaction and Machine Intelligence Technologies Lab"/>
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500&display=swap" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300;400;600&display=swap" rel="stylesheet">
</head>
  <body id="body" class="overflow-auto ">

    <nav id="navbar" class="navbar navbar-expand-md navbar-main fixed-top">

        <a class="navbar-brand" href="index.html"><img src="public/img/simitlab.png" width="200" style="max-height: 71px;max-width: 200px;" alt=""></a>
        <a id="nav-collapse-button" class="nav-add mr-3 no-d-lg "><i id="bars" class="fas fa-bars"></i></a>

        <!-- Navbar links -->
        <div class="no-d-sm">
          <ul class="navbar-nav">
            <li class="nav-item">
                <a class="nav-link" href="index.html">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link  active" href="projects.html">Projects</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="team.html">Team</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="publications.html">Publications</a>
            </li>
          </ul>

        </div>

        <div id="collapse-navbar" class="collapse-navbar not-visible d-sm">
            <div class="container collapse-container">
                <div class="row justify-content-center mb-5">
                    <div class="col-6">
                       <a href="index.html" class="navlink"> <p class="text-center text-white navbar-small-link">Home</p></a>
                    </div>
                </div>
                <div class="row justify-content-center mb-5">
                    <div class="col-6">
                       <a href="projects.html" class="navlink"> <p class="text-center text-white navbar-small-link">Projects</p></a>
                    </div>
                </div>
                <div class="row justify-content-center mb-5">
                    <div class="col-6">
                        <a href="team.html" class="navlink"> <p class="text-center text-white navbar-small-link">Team</p></a>
                    </div>
                </div>
                <div class="row justify-content-center mb-5">
                    <div class="col-6">
                        <a href="publications.html" class="navlink">  <p class="text-center text-white navbar-small-link">Publications</p> </a>
                    </div>
                </div>
            </div>
        </div>
      </nav>

      <div class="container-fluid breadcrump">
        <div class="row">
            <div class="col-12">
                <h1 class="header text-white">Projects</h1>
            </div>
        </div>
    </div>

        <div class="container-fluid" style="margin-top: 5rem !important">
            <div class="row justify-content-center mt-5">
                <div class="col-6 col-md-4 text-center project-header-div-left active-left" id="current">
                    <span class="project-header-text">Curent</span>
                </div>
                <div class="col-6 col-md-4 text-center project-header-div-right" id="past">
                   <span class="project-header-text">Past</span>
                </div>
            </div>

            <div class="row justify-content-center mt-5" id="currentSection">
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="plus1" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Principal Investigator, "Bitüm Penetrasyon Tahmini", funded by Tüpraş.</h4>
                            </div>
                        </div>
                        <div id="proj1" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: March 2018 <br>
                                    End date: September 2018 <br> <br>
                                    Sponsors: Tüpraş</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                    <div class="container">
                        <div id="plus2" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Management Committee Member, "Indoor Living Space Improvement: Smart Habitat for the Elderly"</h4>
                            </div>
                        </div>
                        <div id="proj2" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: October 2017 <br>
                                    End date: October 2021 <br> <br>
                                   Sponsors: European Cooperation in Science and Technology (COST) Programmeş</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                  <div class="container">
                    <div id="plus3" class="row">
                        <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                        <div class="col align-self-center">
                            <h4 class="project">MULTI-modal Imaging of FOREnsic SciEnce Evidence - tools for Forensic Science (MUTIFORESEE)</h4>
                        </div>
                    </div>
                    <div id="proj3" class="row" style="display: none;">
                        <div class="col-2 col-md-1"></div>
                        <div class="col align-self-center">
                            <h3 class="project-alt">Start date: March 2017 <br>
                                End date: March 2021 <br> <br>
                                Sponsors: European Cooperation in Science and Technology (COST) Programme</h3>
                        </div>
                    </div>
                </div>
                </div>
            </div>


            <div class="row justify-content-center mt-5 d-none" id="pastSection">
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus1" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">The European Network on Integrating Vision and Language (iV&L Net)</h4>
                            </div>
                        </div>
                        <div id="pastProj1" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: March 2014 <br>
                                    End date: March 2018 <br> <br>
                                    Abstract:<br> <t style="font-weight: 400;">Combining Computer Vision and Language Processing For Advanced Search, Retrieval, Annotation and Description of Visual Data.</t> <br><br>
                                    Sponsors: European Union under European Cooperation in Science and Technology (COST) Programme</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus2" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Algorithms, Architectures and Platforms for Enhanced Living Environments (AAPELE)</h4>
                            </div>
                        </div>
                        <div id="pastProj2" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: November 2013 <br>
                                    End date: November 2017 <br> <br>
                                    Abstract: <br> <t style="font-weight: 400;"> Ambient Assisted Living (AAL) is an area of research based on Information and Communication Technologies (ICT), medical research, and sociological research. AAL is based on the notion that technology and science can provide improvements in the quality of life for people in their homes, and that it can reduce the financial burden on the budgets of European healthcare providers. The concept of Enhanced Living Environments (ELE) refers to the AAL area that is more related with the Information and Communication Technologies. To design, plan, deploy and operate, an AAL system often comprehends the integration of several scientific areas. The Architectures, Algorithms and Platforms for Enhanced Living Environments (AAPELE) COST Action addresses the issues of defining software, hardware and service architectures for AAL, on studying and creating more efficient algorithms for AAL, particularly those related to the processing of large amounts of data and of biosignals in lossy environments, and on the research of protocols for AAL or, with more detail, on studying communication and data transmission protocols for AAL. This Action aims to promote interdisciplinary research on AAL, through the creation of a research and development community of scientists and entrepreneurs, focusing on AAL algorithms, architectures and platforms, having in view the advance of science in this area and the development of new and innovative solutions.
                                        <br> <br>
                                        <b>Sponsors:</b> European Union under European Cooperation in Science and Technology (COST) Programme
                                        <br><br>
                                        <b>Partner(s):</b> <a href="Partner(s): http://www.cost.eu/domains_actions/ict/Actions/IC1303?management" target="_blank">Link</a>
                                    </h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus3" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Multimodal Face Processing</h4>
                            </div>
                        </div>
                        <div id="pastProj3" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: June 2013 <br>
                                    End date: May 2017 <br> <br>
                                    Partner(s): Istanbul Technical University, SiMiT Lab <br><br>
                                    Sponsors: European Union under the FP7 Marie Skłodowska-Curie Actions</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus4" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">De-identification for Privacy Protection in Multimedia Content.</h4>
                            </div>
                        </div>
                        <div id="pastProj4" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: March 2013 <br>
                                    End date: March 2017 <br> <br>
                                    Partner(s): <a href="http://www.cost.eu/domains_actions/ict/Actions/IC1303?management" target="_blank">Link</a>
                                    <br><br>
                                    Sponsors: European Union under European Cooperation in Science and Technology (COST) Programme</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus5" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Artificial Vision for Assisting Visually Impaired in Social Interactions</h4>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus6" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Game Development for Visually Impaired to Improve Sight (Görme Yetisini İyileştirmeye Yönelik Mobil Oyun Geliştirme)</h4>
                            </div>
                        </div>
                        <div id="pastProj6" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: Dec. 2015<br>
                                    End date: May 2016 <br> <br>
                                    Partner(s): Istanbul Technical University, SiMiT Lab <br> <br>
                                    Sponsors: Türk Telekom</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus7" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Content-based Fast Image Retrieval</h4>
                            </div>
                        </div>
                        <div id="pastProj7" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: Jan. 2016 <br>
                                    End date: June 2016 <br> <br>
                                    Partner(s): Istanbul Technical University, SiMiT Lab <br> <br>
                                    Sponsors: The Scientific and Technological Research Council of Turkey (TUBITAK)</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus8" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Collaborative Annotation of Multi-Modal, Multi-Lingual and Multimedia documents (CAMOMILE)</h4>
                            </div>
                        </div>
                        <div id="pastProj8" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: October 2012 <br>
                                    End date: September 2015 <br> <br>
                                    Abstract: <br> <t style="font-weight: 400;"> Human activity is constantly generating large volumes of heterogeneous data, in particular via the Web. These data can be collected and explored to gain new insights in social sciences, linguistics, economics, behavioural studies as well as artificial intelligence and computer sciences. In this regard, 3M (multimodal, multimedia, multilingual) data could be seen as a paradigm of sharing an object of study, human data, between many scientific domains. But, to be really useful, these data should be annotated, and available in very large amounts. Annotated data is useful for computer sciences which process human data with statistical-based machine learning methods, but also for social sciences which are more and more using the large corpora available to support new insights, in a way which was not imaginable few years ago. However, annotating data is costly as it involves a large amount of manual work, and in this regard 3M data, for which we need to annotate different modalities with different levels of abstraction is especially costly. Current annotation framework involves some local manual annotation, with the help sometimes of some automatic tools (mainly pre-segmentation). The proposal aims at developing a first prototype of collaborative annotation framework on 3M data, in which the manual annotation will be done remotely on many sites, while the final annotation will be localized on the main site. Furthermore, with the same principle, some systems devoted to automatic processing of the modalities (speech, vision) present in the multimedia data will help the transcription, by producing automatic annotations. These automatic annotations are done remotely in each expertise point, which will be then combined locally to produce a meaningful help to the annotators. In order to develop this new annotation concept, we will test it on a practical case study: the problem of person annotation (who is speaking?, who is seen?) in video, which needs collaboration of high level automatic systems dealing with different media (video, speech, audio tracks, OCR, ...). The quality of the annotated data will be evaluated through the task of person retrieval. This new way to envision the annotation process, should lead to some methodologies, tools, instruments and data that are useful for the whole scientific community who have interest in 3M annotated data; to support this will, all the work will be supervised by a committee which will contain representatives from the main international organizations dealing with language resources and evaluation.</t><br><br>
                                    Partner(s):Istanbul Technical University, SiMiT Lab, LIMSI-CNRS, LIG-CNRS, IMMI-CNRS (France), UPC (Spain), CRP-Lippmann (Luxembourg) <br> <br>
                                    Sponsors: FP7 ERA-NET CHIST-ERA Grant</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus9" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">A Unified Framework for Face Analysis</h4>
                            </div>
                        </div>
                        <div id="pastProj9" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: October 2013<br>
                                    End date: September 2015 <br> <br>
                                    Abstract: <br> <t style="font-weight: 400;"> The focus of this project is to develop a unified framework for face analysis with the objective of building a system that receives a face image or video and generates several types of information by processing the face with a shared, optimized structure, enabling real-time processing.</t><br><br>
                                    Partner(s): Istanbul Technical University, SiMiT Lab <br> <br>
                                    Sponsors: The Scientific and Technological Research Council of Turkey (TUBITAK) under the Career Development Programme</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus10" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Exploiting Smartphones and Crowdsourcing for Environmental Monitoring</h4>
                            </div>
                        </div>
                        <div id="pastProj10" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: September 2013 <br>
                                    End date: August 2014 <br> <br>
                                    Abstract: <br> <t style="font-weight: 400;"> Environmental sustainability is an essential requirement that the modern world has to meet. An important task for having sustainable environment is developing efficient monitoring methods. In this project, we focus on this task and propose an approach that exploits smartphones and crowdsourcing for environmental monitoring. The project consists of a data collection application that enables smartphone users take pictures of plants and send them to a central server and advanced computer vision methods that enable automatic identification of plant species. Based on these developed tools and technologies, in the long term, the objective is to build a smartphone application as an electronic field guide for plants and to devise statistical techniques to model and monitor distribution of plant species.</t><br><br>
                                    Partner(s): Istanbul Technical University, SiMiT Lab <br> <br>
                                    Sponsors: Turk Telekom Argela Collaborative Research Award</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus11" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Mobile Face Analysis</h4>
                            </div>
                        </div>
                        <div id="pastProj11" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: January 2014 <br>
                                    End date: December 2014 <br> <br>
                                    Abstract: <br> <t style="font-weight: 400;"> In the past few years, the digital entertainment world has focused on human-machine interaction on many different platforms. This interaction has grown in importance in the market, where the mobile devices and mobile games got the largest slice and massive amounts of users got attracted by augmented reality based applications. When the domination of computers and mobile devices over our social lives is concerned, we can easily realize that, popularity of these technologies was a very expected output. It may also possible to decrease this asociality of society with proper usage of these resources. In the project, inspired with this idea, developing an augmented reality aided mobile game to socialize players has been planned. Considering that the game aims to promote socializing, it is clear that multiplayer interaction is also one of the main focuses beside human-machine interaction. Favoring this aim may lead this game to include aspects, which enables players to engage physically with other players, using a camera. All these features are well fit for a mobile game application. In a nutshell, this project aims to build a mobile game that will encourage players to socialize with augmented reality and multiplayer features. The application will utilize image processing and face detection techniques to accomplish its unique gameplay elements.</t><br><br>
                                    Partner(s): Istanbul Technical University, SiMiT Lab <br> <br>
                                    Sponsors: Avea Labs Research Grant</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus12" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Facial Image Processing for Human-Computer Interaction</h4>
                            </div>
                        </div>
                        <div id="pastProj12" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: January 2013 <br>
                                    End date: March 2014<br> <br>
                                    Abstract: <br> <t style="font-weight: 400;">One of the most important aspects of the next generation user interfaces is being human-centered. In human-centered user interfaces, the machines are expected to adapt themselves to the user in order to have a natural, efficient interaction. The most important source of information that enables machines to customize themselves according to the user is faces. In this project, we will focus on this topic: efficient processing of faces and receiving information about the user to provide a natural user interaction.</t><br><br>
                                    Partner(s): Istanbul Technical University, SiMiT Lab <br> <br>
                                    Sponsors: Tüpraş</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
                <div class="col-12 col-md-8">
                    <div class="container">
                        <div id="pastPlus13" class="row">
                            <div class="col-2 col-md-1"><i class="fas fa-plus plus"></i></div>
                            <div class="col align-self-center">
                                <h4 class="project">Affective Computing for Mobile HCI: Integrating Efforts for an Industry-informed Contemporary Module</h4>
                            </div>
                        </div>
                        <div id="pastProj13" class="row" style="display: none;">
                            <div class="col-2 col-md-1"></div>
                            <div class="col align-self-center">
                                <h3 class="project-alt">Start date: April 2012<br>
                                    End date: December 2014 <br> <br>
                                    Abstract: <br> <t style="font-weight: 400;">Affective and behavioural computing aims to equip computing devices (personal PCs, smart phones) with the means to interpret, understand, and respond to human communicative behaviour, emotions, moods, and, possibly, intentions in a naturalistic way - similar to the way humans rely on their senses to assess each other’s communicative and affective state. In the last 15 years researchers in the affective computing fields have invested increased effort into creating perceptive and intelligent systems with elaborate emotional and social skills. Such efforts have been bearing fruit – the affective computing field has undergone a rapid growth and has become a highly active area of research and practice. Despite such notable developments, the academic and teaching aspect of affective computing has largely been neglected. Academic efforts on offering modules and courses in these areas are relatively new. Additionally, existing teaching and research efforts have never been brought together to shed light into the issues in designing, teaching, sharing material/resources and experiences by academics. Therefore, this project aims to become the initial but crucial step toward bringing together researchers and academics from relevant yet diverse research fields to discuss the issues and the challenges pertinent in all relevant fields, explore the possible solutions, set key standards, and define future module and course design directions and teaching strategies for making affective computing tangible for greater number of university students as well as industry partners, in particular companies in mobile and telecommunications industry, that will potentially benefit from employing these students.
                                    </t><br><br>
                                    Partner(s): Istanbul Technical University, SiMiT Lab, Queen Mary University of London, Avea Labs <br> <br>
                                    Sponsors: British Council under the UK-Turkey Knowledge Partnership Programme</h3>
                            </div>
                        </div>
                    </div>
                  <br>
                </div>
            </div>
        </div>

        <section id="footer" class=" footer">
            <footer >
                <div class="container">
                    <div class="row">
                        <div class="col-12">
                            <h1 class="header">Contact</h1>
                            <div class="arrow">&nbsp;</div>
                        </div>
                    </div>
                </div>
                <div class="container mt-5">
                    <div class="row">
                        <div class="col-12 text-center">
                            <p class="copyright">Prof. Dr. Hazım Kemal EKENEL <br>
                                Faculty of Computer and Informatics <br>
                                Istanbul Technical University <br>
                                Maslak, İstanbul, 34469 <br></p>
                        </div>
                    </div>
                    <div class="row mt-5">
                        <div class="col-0 col-md-2"></div>
                        <div class="col-12 col-md-4 text-center">
                           <a class="social"  href="http://web.itu.edu.tr/ekenel/" target="_blank"> <span><i class="fas fa-globe"></i> web.itu.edu.tr/ekenel</span></a>
                        </div>
                        <br><br>
                        <div class="col-12 col-md-4 text-center">
                           <a class="social"  href="mailto:ekenel@itu.edu.tr" target="_blank"> <span><i class="far fa-envelope"></i></i> ekenel@itu.edu.tr</span></a>
                        </div>
                        <div class="col-0 col-md-2"></div>
                    </div>
                    <div class="row mt-5">
                       <div class="col-12 text-center">
                            <p class="copyright">Copyright 2020 &copy; İTÜ SIMIT LAB</p>
                       </div>
                    </div>
                </div>
            </footer>
        </section>



    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/owl.carousel.min.js"></script>
    <script src="public/js/script-projects.js"></script>
</body>
</html>